\documentclass[11pt]{article}

\usepackage{natbib}
\usepackage{xcolor}
\usepackage[T1]{fontenc}
\usepackage{fourier}
\usepackage[utf8]{inputenc}
\usepackage[hidelinks]{hyperref}
\usepackage{slashbox}

\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}\PackageWarning{TODO:}{#1!}}
\newcommand*{\np}{\par\noindent\newline}

\title{Agent Based Modelling of the Formation of Social Preferences}
\author{S Pardy}
\begin{document}
\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for horizontal lines, change thickness here
	
	\center % Centre everything on the page
	
	%------------------------------------------------
	%	Headings
	%------------------------------------------------
	
	\textsc{\LARGE Monash University}\\[1.5cm]	
	\textsc{\Large Bachelor of Science (Honours)}\\[0.5cm] % Major heading such as course name
	
	\textsc{\large Computational Science}\\[0.5cm] % Minor heading such as course title
	
	%------------------------------------------------
	%	Title
	%------------------------------------------------
	
	\HRule\\[0.4cm]
	
	{\huge\bfseries Agent Based Modelling of the Formation of Social Preferences}\\[0.4cm]
	
	\HRule\\[1.5cm]
	
	%------------------------------------------------
	%	Author(s)
	%------------------------------------------------
	
	\begin{minipage}{0.4\textwidth}
		\begin{flushleft}
			\large
			\textit{Author}\\
			Sam \textsc{Pardy}
		\end{flushleft}
	\end{minipage}
	~
	\begin{minipage}{0.4\textwidth}
		\begin{flushright}
			\large 
			\textit{Student ID}\\
		25940783   
		\end{flushright}
	\end{minipage}
	\vfill
	\vfill
	{\large
	\textit{Supervisor}\\
	Dr. Julian \textsc{Garcia}}
	
	%------------------------------------------------
	%	Date
	%------------------------------------------------
	
	\vfill\vfill\vfill % Position the date 3/4 down the remaining page
	
	{\large\today} % Date

	\vfill % Push the date up 1/4 of the remaining page
	
\end{titlepage}
\hypersetup{colorlinks, citecolor=black, filecolor=black, linkcolor=black urlcolor=black}

\newpage
\tableofcontents
\newpage
\section{Introduction}
Why do we cooperate to the level that we do? Paying your taxes; following the
road rules; these are situations in which it would be beneficial for an
individual to be-cooperative, yet the vast majority of people are not. The
reason why is still unknown. \textcolor{red}{Cooperation is listed as one of
the open questions of science THERE IS A CITATION FOR THIS}
\np The research proposed herein is intended to contribute to the explanation
of cooperation by addressing questions in \textit{Evolutionary Game Theory}
with a particular focus on the the formation of social preferences that result
in cooperative action amongst agents. This is an interdisciplinary research
area, spanning biology, economics, philosophy and computer science.This piece
will begin by laying out the broader context of the field and existing research
before motivating the proposed research by describing the open questions in the
existing literature.
\np I first outline basic game theory before describing a version of
game theory that includes \textit{preferences} and then \textit{social
preferences}. We then move on to discussing evolutionary game theory, and the
evolution of social preferences. The second main area of context that must be
outlined is that of agent based modelling (ABM). We discuss ABM in a broad way
- including evolutionary techniques and reinforcement learning - before moving
onto an examination of methods to simulate social preferences in artificial
agents.
\np With the broader research space outlined, the piece moves onto a
description of the proposed research in detail. Including a specific account of
the questions the research intends to answer and the outcomes it intends to
achieve, as well as the methods used to do so. The piece concludes with a
preliminary timeline that the research project will adhere to. 
\todo{PUT RESEARCH QUESTION HERE}
\section{Research Context}
\subsection{What is modelling social interactions?}
Strategic interactions occur when agents interact in a way such that the
outcome of the interaction for one, is dependent not  only on their decision
but on the decision of the agent(s) that they are interacting with
(`playing against'). There is no shortage of examples of interactions that can
be characterized in this way - from playing chess; to investing in the stock
market; to choosing which route to take on your daily commute; to political
parties campaigning during an election.
\np To give an example, when you are playing chess whether your move is a good
one or not depends on the moves your opponent intends to make in future. So,
you take this into account - your move depends on what you think you opponent
is going to do. However, your opponent knows this also, so, their move depends
on what they think you're going to do. So, really your move depends on what you
think your opponent thinks you're going to do. Of course, this recursion can be
followed ad infinitum, so we need some formal way to model these interactions -
this is where Game Theory becomes important.
\subsubsection{Games}
Formally, a person is playing a game in any situation in which the result they
achieve is determined not only by their own decision but by the decisions of
one or more other agents involved \cite{angner_course_2012}. Game theory is the
study of such `strategic' interactions.
The structure of a game includes:
\begin{itemize}
	\item the finite set, N, of players;
	\item for each player, i $\in$ N, a set $A_i$, of actions available to that
	player $N_i$;
	\item and, for each player, i $\in$ N, the set $P_i$ of pay-offs associated
	with the available actions.
\end{itemize}
\cite{osborne_course_1994}
\np Below is an example of the payoff structure of one of the most famous games
that deals with cooperation: 
\paragraph{The Prisoner's Dilemma:}\mbox{}\\
In the Prisoner's Dilemma, two criminals are being interrogated
separately with the view to get them to turn on one another - if they both
remain silent, they will each receive only a small jail sentence but if one
stays silent and the other talks then the one who talks will be released while
the one who doesn't will receive a large jail sentence. However, if they both
talk, blaming the other, then they will both receive a medium jail sentence.
Since the jail sentence each player receives depends on the other player's
action, this is a game! A part of what makes selecting the best action
difficult is that the players decide their action simultaneously and so do not
know how the other will act. The payoff matrix can be written as follows:
\begin{center}
   \begin{tabular}{|l||*{5}{c|}}\hline
	\backslashbox{Prisoner A}{Prisoner B}
	&\makebox[7em]{Remain Silent}&\makebox[7em]{Talk}\\\hline\hline
	Remain Silent & -1, -1 & -5, 0\\\hline
	Talk & 0, -5 & -3, -3 \\\hline
	\end{tabular}
\end{center}\mbox{}\\
In the table above, prisoner A (the row player) chooses between the rows and
receives the payoff on the left hand side of the cell while prisoner B (the
column player) chooses between the columns and receives the pay off listed on
the right hand side of the cell.
\np In order to reason about the actions that players will take game theoretic
analysis makes several of assumptions about players:
\begin{enumerate}
    \item They target some objective, material pay-off (e.g. the prisoner wants
    to minimize jail time).
    \item Their decisions in pursuit of this pay-off are rational.
    \item They reason in a way that takes into account their beliefs about
    their opponent's action (e.g. prisoner A knows B will also try to minimise
    jail time). 
\end{enumerate}
\cite{osborne_course_1994}
\np The third assumption here is key - players do not just select the action
that is associated with the maximum potential payoff, they select actions to
maximise their payoff relative to what their opponent will do (in their
opponent's pursuit of maximising their payoff). So, players do not select just
one action to take, rather they play a \textit{strategy} that determines their
action under all possible circumstances.

\subsubsection{Strategies \& Nash Equilibrium}
In traditional game theory, the internal desires of the players are  not
taken into consideration. As stated, players are assumed to be motivated by
some objective pay-off. So, when choosing between two (or more) options a
player only cares about her own objective pay off and tries to maximise this.
The `options' that the player selects in a given strategic interaction are
known as strategies. Strategies should not be confused with `moves' or
`actions'. A strategy is not a single move, rather, it's an exhaustive
delineation of how a player will act in any given situation in the game.
\np A strategy can be `pure' or `mixed'. A pure strategy is an unconditional,
complete definition of how the player will play the game - the set of pure
strategies depends only on the game that's being played. For example, if, when
playing rock paper scissors, a player decides to play scissors no matter what,
then that player is implementing a pure strategy. Playing exclusively rock or
paper are the other available pure strategies.
\np When implementing a mixed strategy, the player plays each strategy with
some probability. This probability may be zero for some strategies, but for the
strategy to be considered mixed, the probability that the player plays the
respective strategy must be greater than zero for more than one strategy. So,
if a player plays rock with some probability and scissors with some
probability, but never paper, they are implementing a mixed strategy.
\np The proposed solution to the kinds of strategic games we are interested in
is a Nash Equilibrium \todo{add citation}. Nash Equilibrium is achieved if,
when both players have chosen a strategy, no player can gain anything by
changing their strategy, while their opponent keeps their strategy unchanged. 

\subsubsection{With Preferences}
In the real world, it is difficult to explain all the decisions that people
make if their actions are analysed as being motivated only by their own
material payoff. To include more complex motivations we can introduce
preferences. Preferences map the payoff a player achieves in a game to a
utility function. This utility function is what motivates the player's action.
In a given situation, rather than attempting to maximise payoff players attempt
to maximise utility. Another way to describe preferences, is that they include,
as part of the motivation for action, more than just objective payoff. For
example, buying and consuming a can of soft drink is something that must be
motivated by subjective utility rather than material payoff. Not only does this
\textit{cost} money it is also bad for your health, in fact, it is difficult to
think of any material, objective payoff at all associated with soft drink. So,
even though buying and consuming it is a net loss in terms of payoff, people
buy and consume soft drink all the time. This must be because people derive
some positive \textit{utility} from it, rather than objective payoff.

\subsubsection{Social Preferences}
A preference is considered `social' when a player's utility function is
dependent on their opponent's payoff (or utility). A social preference may
assign positive weight to the opponent's outcome (so our player is "happy" when
their opponent goes well). This is known as an "altruistic" preference.It may
also be the case that the preference assigns negative weight to the opponent's
outcome - so, our player is "envious" when their opponent does well
\cite{angner_course_2012}.
\np Given a two-player game (made up of pay-offs) and the utility functions of
the players, we can write down a \textit{distinct} game based on the utility
each player derives from the pay-offs achieved in each potential result state
in the original game. Here, we run into a problem though. In games that
only consist of strategies and pay-offs it is reasonable to assume that player
A knows the pay-off that her opponent, player B, will achieve in each of the
possible outcome states, and she takes this into account when deciding how to
act. In other words, she knows about \textit{the game she is playing}. However,
when preferences are introduced and the game has been transformed to reflect
this, it is not reasonable to assume that player A knows the \textit{utility}
that B will derive from each given outcome. Player A cannot possibly know about
B's inner feelings and desires. So, how then, does A reason about B's action
when making her decision? We come back to this problem later on. \todo{DO WE?}
\subsection{Evolution of Social Preferences}
It has been purported that cooperation amongst humans is the result of the same
kind of evolutionary forces that shaped cooperation amongst non-human animals
\cite{silk_evolution_2016}. In a nutshell, we assume that the preferences of
people begun as purely selfish (i.e. utility = payoff) and over millennia, were
shaped by Evolution to become prosocial. To model processes such as this, we
can turn to evolutionary game theory. An evolutionary game theory model of
social preference formation includes a population of \textit{agents}, the
majority of which have some utility function r, and are known as Residents.
There is a small portion of the population that known as Mutants who are
motivated by some other utility function, m. The agents in the population are
randomly, pair-wise matched to play some game\footnote{Pairwise matched,
assuming they are playing a two-player game.}. The utility of the players is
what motivates their actions in the game but the  payoff achieved by each
player contributes to their \textit{fitness} which, in association with the
model's selection process, drives their evolutionary success . When the next
generation is produced, the agents with higher fitness are more likely to
reproduce. In this way, preference formation is driven by evolutionary
forces rather than rationality.So, we can end up in a place in which people
buy cans of soft drink and potentially cooperate when it is not in their
immediate interest to do so.
\todo{mention ESS here?}
\subsection{Agent Based Modelling}
Agent based modelling is a kind of computational model that attempts to draw
macro-level conclusions about a system by modelling the actions and behaviours
of individual agents. Agent based modelling is useful in a wide range of areas,
it has been used to evaluate evacuation strategies\cite{taylor_agent-based_2014},
simulate financial markets \cite{deissenberg_eurace:_2008} and investigate
urban sprawl \cite{brown_effects_2006}. We are interested in its applicability
to social preference formation.
\subsubsection{Evolution in Agent Based Models} 
When we talk about modelling evolution of social preferences using an
agent-based model, we're not in the strict sense talking about an entire
population of individual agents that interact with each other to drive
evolution. Instead, the population structure is what is important - the share
of the population that the resident type occupies and the (much smaller) share
that the mutant type occupies. The individuals that are chosen to interact will
be of resident type or mutant type with some probability according to the
population structure. When draw conclusions about evolution of preferences over
time, we do so based on changes to the structure of the population (i.e. what
utility function does the resident have?) \cite{shoham_multiagent_nodate}.
\np An important aspect to this analysis is the notion of \textit{evolutionary
stable strategies}. A strategy is considered to be evolutionary stable if it is
resistant to invaders. That is, strategy $s$ is an evolutionary stable strategy
if for any and all mutant strategies, $m'$, that can be introduced to the
population, $s$ achieves a higher payoff playing against itself and $m'$, than
$m'$ does \cite{shoham_multiagent_nodate}.

\subsubsection{Reinforcement Learning in Agent Based Models}
Most of this piece has been so far dedicated to social preference formation by
evolution, but this is not the only way.
\subsubsection{Social Preferences in Artificial Agents}
\todo{talk about the Peysacovich paper}
\section{Plan \& Methods}
\subsection{Methods}
\todo{Maybe the below sections are unnecessary? Can just do a few paragraphs within the methods sections}
\subsubsection{Evolutionary Game Theory}
\subsubsection{Agent Based Modelling}
\subsubsection{Genetic Programming}
\subsection{Difficulties}
There are two
\subsection{Timeline}
\section{Questions \& Objectives}
In the existing literature, analysis is often done on models in which agents
are matched to play a two player cooperation game in a \textit{uniformly
random} way \todo{add citation}. Firstly, in the real world this is often not
the case - we are more likely to match with some kinds of people than others
(depending on the context we're talking about) and secondly, it has been shown
that the level of assortativity that is present in the matching process has a
large influence on the level of cooperation that is eventually
displayed [\cite{alger_homo_2013}, \todo{cite more?}].

In \cite{alger_homo_2013} the authors perform a static analysis to
conclude that a specific relationship between assortativity and cooperation is
an evolutionary stable strategy. The analysis undertaken in \cite{alger_homo_2013} makes no mention of how likely it is that this outcome
is reached in a dynamic system that is allowed to freely evolve. So, that begs
the first question that the proposed research will attempt to answer:
\np\textbf{How does the formation of social preferences in a dynamically evolving system compare to the static analysis in \cite{alger_homo_2013}?}
\begin{itemize}
\item How likely is the \cite{alger_homo_2013} result to occur, if at all? 
\end{itemize}
Another consideration, is that the shifting of agents' preferences can take
several forms. It can be the traditional sense of evolution, in which traits
are passed down from generation to generation mutating and changing over time,
mimicking Darwinian Evolution. Or, agents can learn within their own lifetime,
via reinforcement learning. So, the next area of interest is:
\np\textbf{How does social preference formation driven by evolution compare to that  of reinforcement learning?}
\begin{itemize}
\item Is one closer to the result in \cite{alger_homo_2013}?
\end{itemize}
These two questions are in service of a more broad, overarching question:
\np\textbf{How does agent based modelling effect the formation of social
preferences?}\np After undertaking the analysis required to answer the first two questions, the piece will be in a position to offer a contribution to
answering this more broad question. This can be done with a comparison between
the results of the previous discussion and analysis in the existing literature
of uniform random matching.
\bibliography{zotero_thesis}
\bibliographystyle{plain}
\end{document}